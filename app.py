import streamlit as st
import os
from pypdf import PdfReader
from groq import Groq
import time
import re
import numpy as np
import cv2

from pdf2image import convert_from_path
from PIL import Image
import pytesseract

# ---------- Paths ----------

SAVE_DIR = "pdf_songs"
os.makedirs(SAVE_DIR, exist_ok=True)

# ---------- Groq client ----------

client = Groq(api_key=os.environ.get("GROQ_API_KEY", ""))


# Tesseract binary path (works on Colab / many Linux servers)
pytesseract.pytesseract.tesseract_cmd = "/usr/bin/tesseract"

# ---------- Helpers ----------

def preprocess_for_ocr(pil_img):
    """Light preprocessing to help Tesseract on scans/handwritten."""
    img = np.array(pil_img.convert("L"))  # grayscale
    img = cv2.resize(img, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_CUBIC)
    img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
    img = cv2.medianBlur(img, 3)
    return Image.fromarray(img)

def looks_noisy(t: str) -> bool:
    """Return True if text looks like OCR garbage (for handwriting etc.)."""
    t = t.strip()
    if len(t) < 80:
        return True
    letters_spaces = sum(c.isalpha() or c.isspace() for c in t)
    ratio = letters_spaces / max(len(t), 1)
    return ratio < 0.5

# ---------- Topic heading ----------

def get_topic_heading(chunk: str, lang: str) -> str:
    if lang == "hindi":
        system_prompt = (
            "à¤¦à¤¿à¤ à¤—à¤ à¤…à¤§à¥à¤¯à¤¯à¤¨ à¤¸à¤¾à¤®à¤—à¥à¤°à¥€ à¤•à¥‡ à¤²à¤¿à¤ à¤¸à¤¿à¤°à¥à¤«à¤¼ 2-6 à¤¶à¤¬à¥à¤¦à¥‹à¤‚ à¤•à¤¾ à¤›à¥‹à¤Ÿà¤¾ à¤Ÿà¥‰à¤ªà¤¿à¤•/à¤¶à¥€à¤°à¥à¤·à¤• à¤²à¤¿à¤–à¥‹à¥¤ "
            "à¤ªà¥‚à¤°à¤¾ à¤µà¤¾à¤•à¥à¤¯ à¤¨à¤¹à¥€à¤‚, à¤•à¥‹à¤ˆ à¤µà¥à¤¯à¤¾à¤–à¥à¤¯à¤¾ à¤¨à¤¹à¥€à¤‚, à¤¸à¤¿à¤°à¥à¤«à¤¼ à¤¶à¥€à¤°à¥à¤·à¤•à¥¤"
        )
    else:
        system_prompt = (
            "For the given study text, write ONLY a very short topic heading "
            "(2-6 words). No sentence, no explanation, just the heading."
        )

    resp = client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": chunk[:800]},
        ],
        temperature=0.2,
        max_tokens=20,
    )
    return resp.choices[0].message.content.strip()

# ---------- Language detection ----------

def detect_language(text):
    hindi_chars = len(re.findall(r'[\u0900-\u097F]', text))
    latin_chars = len(re.findall(r'[A-Za-z]', text))
    total = len(text) or 1
    if hindi_chars / total > 0.05 and hindi_chars > latin_chars:
        return "hindi"
    return "english"

def chunk_text(text, size=1800):
    return [text[i:i+size] for i in range(0, len(text), size)]

# ---------- Song generation (ONLY from extracted text) ----------

@st.cache_data
def make_song(chunk, lang="auto"):
    if lang == "auto":
        lang = detect_language(chunk[:400])

    safe_chunk = chunk.strip()
    if not safe_chunk:
        safe_chunk = "Text is almost empty and noisy; use only these few visible words:\n" + chunk[:200]

    if lang == "hindi":
        system_prompt = """à¤¤à¥à¤®à¥à¤¹à¥‡à¤‚ à¤¨à¥€à¤šà¥‡ à¤¦à¤¿à¤ à¤—à¤ à¤Ÿà¥‡à¤•à¥à¤¸à¥à¤Ÿ (chapter content) à¤•à¥‹ à¤¹à¥€ à¤²à¥‡à¤•à¤°
à¤à¤• à¤›à¥‹à¤Ÿà¤¾, à¤¸à¤°à¤² à¤”à¤° à¤¯à¤¾à¤¦ à¤°à¤–à¤¨à¥‡ à¤²à¤¾à¤¯à¤• à¤¹à¤¿à¤‚à¤¦à¥€ à¤¸à¥à¤Ÿà¤¡à¥€ à¤—à¥€à¤¤ à¤¬à¤¨à¤¾à¤¨à¤¾ à¤¹à¥ˆà¥¤

à¤¸à¤–à¥à¤¤ à¤¨à¤¿à¤¯à¤®:
- à¤¸à¤¿à¤°à¥à¤«à¤¼ à¤¦à¤¿à¤ à¤—à¤ à¤Ÿà¥‡à¤•à¥à¤¸à¥à¤Ÿ à¤®à¥‡à¤‚ à¤œà¥‹ concepts, facts, definitions, examples à¤¹à¥ˆà¤‚, à¤µà¤¹à¥€ à¤‡à¤¸à¥à¤¤à¥‡à¤®à¤¾à¤² à¤•à¤°à¥‹
- à¤•à¥‹à¤ˆ à¤¨à¤¯à¤¾ example, à¤œà¤—à¤¹, à¤•à¤¹à¤¾à¤¨à¥€, à¤µà¥à¤¯à¤•à¥à¤¤à¤¿, organization à¤–à¥à¤¦ à¤¸à¥‡ à¤®à¤¤ à¤¬à¤¨à¤¾à¤“
- à¤…à¤—à¤° à¤•à¥à¤› à¤¸à¤®à¤ à¤®à¥‡à¤‚ à¤¨à¤¹à¥€à¤‚ à¤†à¤¤à¤¾, à¤‰à¤¸à¥‡ à¤›à¥‹à¤¡à¤¼ à¤¦à¥‹; à¤…à¤ªà¤¨à¥‡ à¤¸à¥‡ à¤•à¥à¤› à¤®à¤¤ à¤œà¥‹à¤¡à¤¼à¥‹
- à¤›à¤¾à¤¤à¥à¤°à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤†à¤¸à¤¾à¤¨ à¤¹à¤¿à¤‚à¤¦à¥€, à¤›à¥‹à¤Ÿà¥€ à¤²à¤¾à¤‡à¤¨à¥‡à¤‚, à¤•à¥‹à¤°à¤¸ à¤”à¤° à¤¦à¥‹à¤¹à¤°à¤¾à¤µ
- à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ à¤¸à¤¿à¤°à¥à¤«à¤¼ à¤—à¥€à¤¤ à¤•à¥‡ à¤¬à¥‹à¤² à¤¹à¥‹; explanation à¤¯à¤¾ "à¤®à¥ˆà¤‚ à¤¨à¤¹à¥€à¤‚ à¤•à¤° à¤¸à¤•à¤¤à¤¾" à¤®à¤¤ à¤²à¤¿à¤–à¥‹
"""
    else:
        system_prompt = """You are given ONLY textbook content for a specific chapter.
Turn ONLY this content into a short, simple, easy-to-memorize study song.

STRICT rules:
- Use ONLY concepts, terms, definitions, and examples that appear in the given text
- Do NOT add any new topics, places, names, stories, or facts that are not clearly present
- If something is unclear or missing, SKIP it instead of inventing details
- Student-friendly, short lines with a small chorus
- Output ONLY song lyrics, never explanations or meta-comments
"""

    response = client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": safe_chunk}
        ],
        temperature=0.5,
        max_tokens=450
    )
    return response.choices[0].message.content.strip()

# ---------- UI ----------

st.set_page_config(page_title="PDF Study Song (HI+EN+OCR)", layout="wide")

st.title("ğŸµ PDF to Study Song Generator ğŸµ")
st.markdown("**English / à¤¹à¤¿à¤‚à¤¦à¥€ PDFs à¤•à¥‡ à¤²à¤¿à¤ à¤•à¤¾à¤® à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆ (printed + scanned). Handwritten is experimental.**")

col1, col2 = st.columns([1, 3])

with col1:
    lang_mode = st.radio(
        "ğŸŒ Language Mode:",
        ["ğŸš€ Auto-detect", "ğŸ‡ºğŸ‡¸ Force English", "ğŸ‡®ğŸ‡³ Force Hindi", "both english and hindi"],
        index=0
    )

with col2:
    st.info("ğŸ“š Printed / scanned textbook PDFs à¤ªà¤° best results. Handwritten notes à¤ªà¤° OCR à¤¹à¤®à¥‡à¤¶à¤¾ accurate à¤¨à¤¹à¥€à¤‚ à¤¹à¥‹à¤—à¤¾à¥¤")

uploaded_file = st.file_uploader("ğŸ“ Upload PDF", type="pdf")

if uploaded_file is not None:
    # Local path works both in Colab and cloud
    tmp_pdf_path = os.path.join(".", uploaded_file.name)
    with open(tmp_pdf_path, "wb") as f:
        f.write(uploaded_file.read())

    noisy_pages = 0

    with st.spinner("ğŸ” Reading PDF (text first, OCR for image/handwritten pages)..."):
        reader = PdfReader(tmp_pdf_path)
        text = ""
        page_count = len(reader.pages)
        prog = st.progress(0.0)

        for i, page in enumerate(reader.pages):
            t = page.extract_text() or ""
            clean = t.strip()

            # If almost no text, assume scan / handwritten -> OCR
            if len(clean) < 40:
                images = convert_from_path(
                    tmp_pdf_path, dpi=300, first_page=i+1, last_page=i+1
                )
                img = preprocess_for_ocr(images[0])
                t = pytesseract.image_to_string(img, lang="hin+eng")
                if looks_noisy(t):
                    noisy_pages += 1

            text += t + "\n"
            prog.progress((i + 1) / page_count)

    if noisy_pages > page_count * 0.6:
        st.error("âŒ Most pages look like unreadable handwriting / noisy OCR. Songs would be nonsense. Try a clearer scan or typed PDF.")
        st.stop()

    detected_lang = detect_language(text[:2000])
    lang_display = "ğŸ‡®ğŸ‡³ Hindi" if detected_lang == "hindi" else "ğŸ‡ºğŸ‡¸ English"

    m1, m2, m3 = st.columns(3)
    with m1:
        st.metric("ğŸ“„ Pages", page_count)
    with m2:
        st.metric("ğŸ”¤ Characters", len(text))
    with m3:
        st.metric("ğŸ—£ï¸ Detected", lang_display)

    if noisy_pages:
        st.warning(f"âš ï¸ {noisy_pages} page(s) had very noisy OCR (likely handwritten / bad scan). Output may be imperfect.")

    st.success(f"âœ… PDF ready! Detected: **{lang_display}**")

    if st.button("ğŸ¶ Generate Study Song", type="primary", use_container_width=True):
        if lang_mode == "ğŸš€ Auto-detect":
            final_lang = detected_lang
        elif "Hindi" in lang_mode:
            final_lang = "hindi"
        else:
            final_lang = "english"

        chunks = chunk_text(text)
        st.info(f"ğŸ¼ Creating {len(chunks)} verse(s) in **{final_lang.upper()}** â€¦")

        bar = st.progress(0.0)
        status = st.empty()
        final_song = ""

        for i, chunk in enumerate(chunks):
            status.text(f"âœï¸ Generating verse {i+1}/{len(chunks)} â€¦")

            topic = get_topic_heading(chunk, final_lang)
            verse = make_song(chunk, final_lang)

            final_song += (
                f"**ğŸ§¾ Topic:** {topic}\n\n"
                f"**ğŸµ Verse {i+1} ğŸµ**\n\n"
                f"{verse}\n\n---\n\n"
            )

            bar.progress((i + 1) / len(chunks))
            time.sleep(0.2)

        st.subheader("ğŸ¤ Your Complete Study Song")
        st.markdown(final_song)

        fname = uploaded_file.name.replace(".pdf", f"_{final_lang}_study_song.txt")
        out_path = os.path.join(SAVE_DIR, fname)
        with open(out_path, "w", encoding="utf-8") as f:
            f.write(final_song)

        st.success(f"ğŸ’¾ Saved at: `{out_path}`")
        st.download_button(
            "ğŸ“¥ Download Song",
            data=final_song,
            file_name=fname,
            mime="text/plain",
            use_container_width=True
        )
