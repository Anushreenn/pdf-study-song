import streamlit as st
import os
from pypdf import PdfReader
from groq import Groq
import time
import re
import io
from PIL import Image
import pytesseract

# Page config
st.set_page_config(page_title="PDF Study Song (HI+EN+OCR)", layout="wide")

# Groq client
@st.cache_resource
def get_client():
    return Groq(api_key=os.environ.get("GROQ_API_KEY"))

client = get_client()

SAVE_DIR = "pdf_songs"

# ---------- Helpers ----------
def preprocess_for_ocr(pil_img):
    """Light preprocessing to help Tesseract on scans/handwritten."""
    from PIL import ImageEnhance
    img = pil_img.convert("L")  # grayscale
    enhancer = ImageEnhance.Contrast(img)
    img = enhancer.enhance(2)
    return img

def looks_noisy(t: str) -> bool:
    """Return True if text looks like OCR garbage."""
    t = t.strip()
    if len(t) < 80:
        return True
    letters_spaces = sum(c.isalpha() or c.isspace() for c in t)
    ratio = letters_spaces / max(len(t), 1)
    return ratio < 0.5

# ---------- Topic heading ----------
def get_topic_heading(chunk: str, lang: str) -> str:
    if lang == "hindi":
        system_prompt = (
            "‡§¶‡§ø‡§è ‡§ó‡§è ‡§Ö‡§ß‡•ç‡§Ø‡§Ø‡§® ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§ø‡§∞‡•ç‡§´‡§º 2-6 ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡§æ ‡§õ‡•ã‡§ü‡§æ ‡§ü‡•â‡§™‡§ø‡§ï/‡§∂‡•Ä‡§∞‡•ç‡§∑‡§ï ‡§≤‡§ø‡§ñ‡•ã‡•§ "
            "‡§™‡•Ç‡§∞‡§æ ‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§®‡§π‡•Ä‡§Ç, ‡§ï‡•ã‡§à ‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ ‡§®‡§π‡•Ä‡§Ç, ‡§∏‡§ø‡§∞‡•ç‡§´‡§º ‡§∂‡•Ä‡§∞‡•ç‡§∑‡§ï‡•§"
        )
    else:
        system_prompt = (
            "For the given study text, write ONLY a very short topic heading "
            "(2-6 words). No sentence, no explanation, just the heading."
        )

    resp = client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": chunk[:800]},
        ],
        temperature=0.2,
        max_tokens=20,
    )
    return resp.choices[0].message.content.strip()

# ---------- Language detection ----------
def detect_language(text):
    hindi_chars = len(re.findall(r'[\u0900-\u097F]', text))
    latin_chars = len(re.findall(r'[A-Za-z]', text))
    total = len(text) or 1
    if hindi_chars / total > 0.05 and hindi_chars > latin_chars:
        return "hindi"
    return "english"

def chunk_text(text, size=1800):
    return [text[i:i+size] for i in range(0, len(text), size)]

# ---------- Song generation ----------
@st.cache_data
def make_song(chunk, lang="auto"):
    if lang == "auto":
        lang = detect_language(chunk[:400])

    safe_chunk = chunk.strip()
    if not safe_chunk:
        safe_chunk = "Text is almost empty and noisy; use only these few visible words:\n" + chunk[:200]

    if lang == "hindi":
        system_prompt = """‡§§‡•Å‡§Æ‡•ç‡§π‡•á‡§Ç ‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü (chapter content) ‡§ï‡•ã ‡§π‡•Ä ‡§≤‡•á‡§ï‡§∞
‡§è‡§ï ‡§õ‡•ã‡§ü‡§æ, ‡§∏‡§∞‡§≤ ‡§î‡§∞ ‡§Ø‡§æ‡§¶ ‡§∞‡§ñ‡§®‡•á ‡§≤‡§æ‡§Ø‡§ï ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§∏‡•ç‡§ü‡§°‡•Ä ‡§ó‡•Ä‡§§ ‡§¨‡§®‡§æ‡§®‡§æ ‡§π‡•à‡•§

‡§∏‡§ñ‡•ç‡§§ ‡§®‡§ø‡§Ø‡§Æ:
- ‡§∏‡§ø‡§∞‡•ç‡§´‡§º ‡§¶‡§ø‡§è ‡§ó‡§è ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§Æ‡•á‡§Ç ‡§ú‡•ã concepts, facts, definitions, examples ‡§π‡•à‡§Ç, ‡§µ‡§π‡•Ä ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§ï‡§∞‡•ã
- ‡§ï‡•ã‡§à ‡§®‡§Ø‡§æ example, ‡§ú‡§ó‡§π, ‡§ï‡§π‡§æ‡§®‡•Ä, ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø, organization ‡§ñ‡•Å‡§¶ ‡§∏‡•á ‡§Æ‡§§ ‡§¨‡§®‡§æ‡§ì
- ‡§Ö‡§ó‡§∞ ‡§ï‡•Å‡§õ ‡§∏‡§Æ‡§ù ‡§Æ‡•á‡§Ç ‡§®‡§π‡•Ä‡§Ç ‡§Ü‡§§‡§æ, ‡§â‡§∏‡•á ‡§õ‡•ã‡§°‡§º ‡§¶‡•ã; ‡§Ö‡§™‡§®‡•á ‡§∏‡•á ‡§ï‡•Å‡§õ ‡§Æ‡§§ ‡§ú‡•ã‡§°‡§º‡•ã
- ‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§∏‡§æ‡§® ‡§π‡§ø‡§Ç‡§¶‡•Ä, ‡§õ‡•ã‡§ü‡•Ä ‡§≤‡§æ‡§á‡§®‡•á‡§Ç, ‡§ï‡•ã‡§∞‡§∏ ‡§î‡§∞ ‡§¶‡•ã‡§π‡§∞‡§æ‡§µ
- ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§∏‡§ø‡§∞‡•ç‡§´‡§º ‡§ó‡•Ä‡§§ ‡§ï‡•á ‡§¨‡•ã‡§≤ ‡§π‡•ã; explanation ‡§Ø‡§æ "‡§Æ‡•à‡§Ç ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ" ‡§Æ‡§§ ‡§≤‡§ø‡§ñ‡•ã
"""
    else:
        system_prompt = """You are given ONLY textbook content for a specific chapter.
Turn ONLY this content into a short, simple, easy-to-memorize study song.

STRICT rules:
- Use ONLY concepts, terms, definitions, and examples that appear in the given text
- Do NOT add any new topics, places, names, stories, or facts that are not clearly present
- If something is unclear or missing, SKIP it instead of inventing details
- Student-friendly, short lines with a small chorus
- Output ONLY song lyrics, never explanations or meta-comments
"""

    response = client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": safe_chunk}
        ],
        temperature=0.5,
        max_tokens=450
    )
    return response.choices[0].message.content.strip()

# ---------- PDF Processing with OCR ----------
def extract_pdf_text(uploaded_file):
    text = ""
    noisy_pages = 0
    page_count = 0
    
    # Save uploaded file temporarily
    tmp_pdf_path = f"/tmp/{uploaded_file.name}"
    with open(tmp_pdf_path, "wb") as f:
        f.write(uploaded_file.read())
        uploaded_file.seek(0)  # Reset for later use
    
    try:
        reader = PdfReader(tmp_pdf_path)
        page_count = len(reader.pages)
        
        for i, page in enumerate(reader.pages):
            t = page.extract_text() or ""
            clean = t.strip()
            
            # If almost no text, try OCR
            if len(clean) < 40:
                try:
                    images = convert_from_path(tmp_pdf_path, dpi=200, first_page=i+1, last_page=i+1)
                    img = preprocess_for_ocr(images[0])
                    ocr_text = pytesseract.image_to_string(img, lang='hin+eng')
                    t = ocr_text if not looks_noisy(ocr_text) else t
                    if looks_noisy(ocr_text):
                        noisy_pages += 1
                except:
                    pass
            
            text += t + "\n"
    except:
        text = ""
    
    return text.strip(), page_count, noisy_pages

# ---------- Main UI ----------
st.title("üéµ PDF to Study Song Generator üéµ")
st.markdown("**English / ‡§π‡§ø‡§Ç‡§¶‡•Ä PDFs ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à (printed + scanned). Handwritten is experimental.**")

col1, col2 = st.columns([1, 3])
with col1:
    lang_mode = st.radio(
        "üåê Language Mode:",
        ["üöÄ Auto-detect", "üá∫üá∏ Force English", "üáÆüá≥ Force Hindi", "both english and hindi"],
        index=0
    )

with col2:
    st.info("üìö Printed / scanned textbook PDFs ‡§™‡§∞ best results. Handwritten notes ‡§™‡§∞ OCR ‡§π‡§Æ‡•á‡§∂‡§æ accurate ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã‡§ó‡§æ‡•§")

# Multi-file upload
uploaded_files = st.file_uploader(
    "üìÅ Upload PDF(s)", 
    type="pdf",
    accept_multiple_files=True
)

if uploaded_files:
    all_songs = ""
    
    for uploaded_file in uploaded_files:
        with st.spinner(f"üîç Processing {uploaded_file.name}..."):
            raw_text, page_count, noisy_pages = extract_pdf_text(uploaded_file)
            
            detected_lang = detect_language(raw_text[:2000])
            lang_display = "üáÆüá≥ Hindi" if detected_lang == "hindi" else "üá∫üá∏ English"
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("üìÑ Pages", page_count)
            with col2:
                st.metric("üî§ Characters", len(raw_text))
            with col3:
                st.metric("üó£Ô∏è Detected", lang_display)
            
            if noisy_pages:
                st.warning(f"‚ö†Ô∏è {noisy_pages} noisy page(s) in {uploaded_file.name}")
            
            st.success(f"‚úÖ {uploaded_file.name} ready! ({lang_display})")
            
            # Language selection
            if lang_mode == "üöÄ Auto-detect":
                final_lang = detected_lang
            elif "Hindi" in lang_mode:
                final_lang = "hindi"
            else:
                final_lang = "english"
            
            if st.button(f"üéº Generate Song for {uploaded_file.name}", key=f"gen_{uploaded_file.name}"):
                chunks = chunk_text(raw_text)
                st.info(f"üéº Creating {min(20, len(chunks))} verse(s) from {uploaded_file.name}...")
                
                bar = st.progress(0.0)
                status = st.empty()
                pdf_song = f"\n# üìö {uploaded_file.name}\n\n"
                
                for i, chunk in enumerate(chunks[:20]):  # Max 20 verses
                    status.text(f"‚úçÔ∏è {uploaded_file.name}: Verse {i+1}/{min(20, len(chunks))}")
                    
                    topic = get_topic_heading(chunk, final_lang)
                    verse = make_song(chunk, final_lang)
                    
                    pdf_song += (
                        f"**üßæ Topic:** {topic}\n\n"
                        f"**üéµ Verse {i+1} üéµ**\n\n"
                        f"{verse}\n\n"
                        f"---\n\n"
                    )
                    
                    bar.progress((i + 1) / min(20, len(chunks)))
                    time.sleep(0.5)
                
                all_songs += pdf_song
                
                st.markdown("### üé§ Study Song Generated!")
                st.markdown(pdf_song)
    
    # Final download
    if all_songs:
        st.download_button(
            "üì• Download All Songs",
            data=all_songs,
            file_name="study_songs.txt",
            mime="text/plain"
        )

else:
    st.info("üìÅ Upload PDF(s) to generate study songs!")
